{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.788351019734566\n",
      "-7.788351019734566\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = np.array([[0.1, 0.2, 0.1, 0.4, 0.6], # p(blank | x)\n",
    "              [0.7, 0.3, 0.1, 0.3, 0.2], # p(l1 | x)\n",
    "              [0.1, 0.1, 0.4, 0.2, 0.1], # p(l2 | x)\n",
    "              [0.1, 0.4, 0.4, 0.1, 0.1], # p(l3 | x)\n",
    "              ]) \n",
    "#              t=1  t=2  t=3  t=4  t=5\n",
    "\n",
    "labels = [1, 0, 2, 1] \n",
    "\n",
    "def forward(y, l, blank_idx=0, normalize=True):\n",
    "    #alpha_t(s) is alpha[s, t]\n",
    "    V, T = y.shape\n",
    "    lenl_prime = 2*len(l) + 1\n",
    "    # insert every other label with a blank\n",
    "    l_prime = [blank_idx] + [l[i//2] if i % 2 == 1 else blank_idx for i in range(1, lenl_prime)] #TODO: vectorize\n",
    "    alpha = np.zeros((lenl_prime, T))\n",
    "    # Initialization\n",
    "    alpha[0, 0] = y[blank_idx, 0] # blank at t=0\n",
    "    alpha[1, 0] = y[l[0], 0] # first phoneme at t=0\n",
    "    \n",
    "    # Recursion\n",
    "    for t in range(1, T):\n",
    "        for s in range(lenl_prime):\n",
    "            \n",
    "            if s < lenl_prime - 2*(T-t) - 1:\n",
    "                continue\n",
    "\n",
    "            alpha_bar = alpha[s, t-1] + alpha[s-1, t-1]\n",
    "\n",
    "            if l_prime[s] == blank_idx or l_prime[s-2] == l_prime[s]:\n",
    "                alpha[s, t] = alpha_bar * y[l_prime[s], t]\n",
    "            else:\n",
    "                alpha[s, t] = (alpha_bar + alpha[s-2, t-1]) * y[l_prime[s], t]\n",
    "\n",
    "            if normalize:\n",
    "                C = np.sum(alpha[:, t])\n",
    "                alpha[s, t] = alpha[s, t] / C # alpha_hat_t(s)\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "def backward(y, l, blank_idx=0, normalize=True):\n",
    "    V, T = y.shape\n",
    "    lenl_prime = 2*len(l) + 1\n",
    "    # insert every other label with a blank\n",
    "    l_prime = [blank_idx] + [l[i//2] if i % 2 == 1 else blank_idx for i in range(1, lenl_prime)] #TODO: vectorize\n",
    "    beta = np.zeros((lenl_prime, T))\n",
    "\n",
    "    # Initialization\n",
    "    beta[lenl_prime-1, T-1] = y[blank_idx, T-1] # blank at t=T\n",
    "    beta[lenl_prime-2, T-1] = y[l[-1], T-1] # last phoneme at t=T\n",
    "\n",
    "    # Recursion\n",
    "    for t in range(T-2, -1, -1):\n",
    "        for s in range(lenl_prime):\n",
    "\n",
    "            if s > 2*t:\n",
    "                continue\n",
    "\n",
    "            beta_bar = beta[s, t+1] + beta[s+1, t+1]\n",
    "\n",
    "            if l_prime[s] == blank_idx or l_prime[s+2] == l_prime[s]:\n",
    "                beta[s, t] = beta_bar * y[l_prime[s], t]\n",
    "            else:\n",
    "                beta[s, t] = (beta_bar + beta[s+2, t+1]) * y[l_prime[s], t]\n",
    "\n",
    "            if normalize:\n",
    "                D = np.sum(beta[:, t])\n",
    "                beta[s, t] = beta[s, t] / (D + 1e-20)\n",
    "\n",
    "    return beta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_ctc_loss(y, l, t, blank_idx=0): # do we do this for all t's or what?\n",
    "    # eq. 14\n",
    "    alpha = forward(y, l, blank_idx)\n",
    "    beta = backward(y, l, blank_idx)\n",
    "    lenl_prime = 2*len(l) + 1\n",
    "    l_prime = [blank_idx] + [l[i//2] if i % 2 == 1 else blank_idx for i in range(1, lenl_prime)] #TODO: vectorize\n",
    "    probabilities = alpha * beta\n",
    "    probabilities_t = probabilities[:, t]\n",
    "    \n",
    "    p_l_x = np.sum(probabilities_t / y[l_prime, t])\n",
    "\n",
    "    return np.log(p_l_x)\n",
    "\n",
    "print(compute_ctc_loss(y, labels, -1)) # this?\n",
    "\n",
    "\n",
    "def compute_ctc_loss(y, l, blank_idx=0): # do we do this for all t's or what?\n",
    "    # eq. 8\n",
    "    alpha = forward(y, l, blank_idx)\n",
    "    p_l_x = alpha[-1, -1] + alpha[-2, -1]\n",
    "    return np.log(p_l_x)\n",
    "\n",
    "print(compute_ctc_loss(y, labels)) # or this?\n",
    "\n",
    "# Note: just doing the forward is enough to claculate the loss, but we need the backward for the gradient \n",
    "# (hence the same result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
