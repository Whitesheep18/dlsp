{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC4412E0-PSG.edf\n",
      "Extracting EDF parameters from /home/annareisz/Documents/DeepLearningSignalProcessing/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4412E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5758/3418270808.py:11: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/3418270808.py:11: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/3418270808.py:11: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n"
     ]
    }
   ],
   "source": [
    "sleep_data_dir = Path(\"../../sleep-edf-database-expanded-1.0.0/sleep-cassette/\")\n",
    "file_idx = 200\n",
    "recordings = [x[:6] for x in os.listdir(sleep_data_dir)]\n",
    "psg_files = list(sleep_data_dir.glob(\"*.edf\"))\n",
    "hypnogram_files = list(sleep_data_dir.glob(\"*-Hypnogram.edf\"))\n",
    "\n",
    "# #file that starts with recordings[file_idx]\n",
    "psg_file = [x.name for x in psg_files if x.name.startswith(recordings[0]) and x.name.endswith(\"PSG.edf\")][0]\n",
    "print(psg_file)\n",
    "\n",
    "data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
    "raw_data = data.get_data()\n",
    "# you can get the metadata included in the file and a list of all channels:\n",
    "info = data.info\n",
    "channels = data.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 22 hours\n"
     ]
    }
   ],
   "source": [
    "samples = 7950000\n",
    "sampling_rate_hz = 100\n",
    "duration = samples / sampling_rate_hz\n",
    "hours = duration / 3600\n",
    "print(f\"Duration: {hours:.0f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn hypnogram into 30 seconds labelled data\n",
    "def hypnogram_to_labelled_data(hypnogram, sampling_rate_hz):\n",
    "    data = []\n",
    "    for i in range(len(hypnogram)):\n",
    "        onset = hypnogram.iloc[i]['onset']\n",
    "        duration = hypnogram.iloc[i]['duration']\n",
    "        description = hypnogram.iloc[i]['description']\n",
    "        data.extend([description]*int(duration))\n",
    "    return data\n",
    "\n",
    "def chunk_data(data, window_size):\n",
    "    chunks = []\n",
    "    for i in range(0, len(data), window_size):\n",
    "        chunk = data[i:i+window_size]\n",
    "        if len(chunk) == window_size:\n",
    "            chunks.append(chunk)\n",
    "        else:\n",
    "            print('chunk is not window size, chunk size:', len(chunk), 'window size:', window_size)\n",
    "    return chunks\n",
    "\n",
    "def remove_consecutive_duplicates(arr):\n",
    "    return [arr[i] for i in range(len(arr)) if i == 0 or arr[i] != arr[i-1]]\n",
    "\n",
    "\n",
    "def find_switch_idx(arr):\n",
    "    return [i for i in range(len(arr)) if i == 0 or arr[i] != arr[i-1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Extracting EDF parameters from /home/annareisz/Documents/DeepLearningSignalProcessing/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4412E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk is not window size, chunk size: 1140 window size: 1800\n",
      "Num chunks 47\n",
      "[Errno 2] No such file or directory: 'sleep/SC4412-14.npy'\n",
      "error SC4412\n",
      "1\n",
      "Extracting EDF parameters from /home/annareisz/Documents/DeepLearningSignalProcessing/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4242E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk is not window size, chunk size: 300 window size: 1800\n",
      "Num chunks 45\n",
      "[Errno 2] No such file or directory: 'sleep/SC4242-4.npy'\n",
      "error SC4242\n",
      "2\n",
      "Extracting EDF parameters from /home/annareisz/Documents/DeepLearningSignalProcessing/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4272F0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk is not window size, chunk size: 1500 window size: 1800\n",
      "Num chunks 47\n",
      "[Errno 2] No such file or directory: 'sleep/SC4272-22.npy'\n",
      "error SC4272\n",
      "3\n",
      "Extracting EDF parameters from /home/annareisz/Documents/DeepLearningSignalProcessing/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4592G0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num chunks 34\n",
      "[Errno 2] No such file or directory: 'sleep/SC4592-14.npy'\n",
      "error SC4592\n",
      "4\n",
      "Extracting EDF parameters from /home/annareisz/Documents/DeepLearningSignalProcessing/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4341F0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk is not window size, chunk size: 1500 window size: 1800\n",
      "Num chunks 45\n",
      "[Errno 2] No such file or directory: 'sleep/SC4341-5.npy'\n",
      "error SC4341\n",
      "5\n",
      "Extracting EDF parameters from /home/annareisz/Documents/DeepLearningSignalProcessing/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4201E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk is not window size, chunk size: 1320 window size: 1800\n",
      "Num chunks 46\n",
      "[Errno 2] No such file or directory: 'sleep/SC4201-14.npy'\n",
      "error SC4201\n",
      "6\n",
      "Extracting EDF parameters from /home/annareisz/Documents/DeepLearningSignalProcessing/sleep-edf-database-expanded-1.0.0/sleep-cassette/SC4352F0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
      "/tmp/ipykernel_5758/587321225.py:6: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m psg_file \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m psg_files \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mstartswith(recording) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPSG.edf\u001b[39m\u001b[38;5;124m\"\u001b[39m)][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m hypnogram_file \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m hypnogram_files \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mstartswith(recording) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHypnogram.edf\u001b[39m\u001b[38;5;124m\"\u001b[39m)][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_raw_edf(sleep_data_dir \u001b[38;5;241m/\u001b[39m psg_file)\n\u001b[1;32m      7\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget_data()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Deal with hypnogram\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dlsp/lib/python3.11/site-packages/mne/io/edf/edf.py:1700\u001b[0m, in \u001b[0;36mread_raw_edf\u001b[0;34m(input_fname, eog, misc, stim_channel, exclude, infer_types, include, preload, units, encoding, exclude_after_unique, verbose)\u001b[0m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly EDF files are supported, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m RawEDF(\n\u001b[1;32m   1701\u001b[0m     input_fname\u001b[38;5;241m=\u001b[39minput_fname,\n\u001b[1;32m   1702\u001b[0m     eog\u001b[38;5;241m=\u001b[39meog,\n\u001b[1;32m   1703\u001b[0m     misc\u001b[38;5;241m=\u001b[39mmisc,\n\u001b[1;32m   1704\u001b[0m     stim_channel\u001b[38;5;241m=\u001b[39mstim_channel,\n\u001b[1;32m   1705\u001b[0m     exclude\u001b[38;5;241m=\u001b[39mexclude,\n\u001b[1;32m   1706\u001b[0m     infer_types\u001b[38;5;241m=\u001b[39minfer_types,\n\u001b[1;32m   1707\u001b[0m     preload\u001b[38;5;241m=\u001b[39mpreload,\n\u001b[1;32m   1708\u001b[0m     include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[1;32m   1709\u001b[0m     units\u001b[38;5;241m=\u001b[39munits,\n\u001b[1;32m   1710\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   1711\u001b[0m     exclude_after_unique\u001b[38;5;241m=\u001b[39mexclude_after_unique,\n\u001b[1;32m   1712\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   1713\u001b[0m )\n",
      "File \u001b[0;32m<decorator-gen-202>:12\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, input_fname, eog, misc, stim_channel, exclude, infer_types, preload, include, units, encoding, exclude_after_unique, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/dlsp/lib/python3.11/site-packages/mne/io/edf/edf.py:194\u001b[0m, in \u001b[0;36mRawEDF.__init__\u001b[0;34m(self, input_fname, eog, misc, stim_channel, exclude, infer_types, preload, include, units, encoding, exclude_after_unique, verbose)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# Raw attributes\u001b[39;00m\n\u001b[1;32m    193\u001b[0m last_samps \u001b[38;5;241m=\u001b[39m [edf_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnsamples\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    195\u001b[0m     info,\n\u001b[1;32m    196\u001b[0m     preload,\n\u001b[1;32m    197\u001b[0m     filenames\u001b[38;5;241m=\u001b[39m[input_fname],\n\u001b[1;32m    198\u001b[0m     raw_extras\u001b[38;5;241m=\u001b[39m[edf_info],\n\u001b[1;32m    199\u001b[0m     last_samps\u001b[38;5;241m=\u001b[39mlast_samps,\n\u001b[1;32m    200\u001b[0m     orig_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m     orig_units\u001b[38;5;241m=\u001b[39morig_units,\n\u001b[1;32m    202\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    203\u001b[0m )\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Read annotations from file and set it\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(edf_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtal_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# Read TAL data exploiting the header info (no regexp)\u001b[39;00m\n",
      "File \u001b[0;32m<decorator-gen-184>:12\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, info, preload, first_samps, last_samps, filenames, raw_extras, orig_format, dtype, buffer_size_sec, orig_units, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/dlsp/lib/python3.11/site-packages/mne/io/base.py:300\u001b[0m, in \u001b[0;36mBaseRaw.__init__\u001b[0;34m(self, info, preload, first_samps, last_samps, filenames, raw_extras, orig_format, dtype, buffer_size_sec, orig_units, verbose)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    295\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChannel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mch_without_orig_unit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no associated original unit.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m         )\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# Final check of orig_units, editing a unit if it is not a valid\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# unit\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     orig_units \u001b[38;5;241m=\u001b[39m _check_orig_units(orig_units)\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_orig_units \u001b[38;5;241m=\u001b[39m orig_units \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mdict\u001b[39m()  \u001b[38;5;66;03m# always a dict\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_projectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/dlsp/lib/python3.11/site-packages/mne/_fiff/utils.py:45\u001b[0m, in \u001b[0;36m_check_orig_units\u001b[0;34m(orig_units)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     44\u001b[0m valid_units \u001b[38;5;241m=\u001b[39m _get_valid_units()\n\u001b[0;32m---> 45\u001b[0m valid_units_lowered \u001b[38;5;241m=\u001b[39m [unit\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m valid_units]\n\u001b[1;32m     46\u001b[0m orig_units_remapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(orig_units)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ch_name, unit \u001b[38;5;129;01min\u001b[39;00m orig_units\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Be lenient: we ignore case for now.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dlsp/lib/python3.11/site-packages/mne/_fiff/utils.py:45\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     44\u001b[0m valid_units \u001b[38;5;241m=\u001b[39m _get_valid_units()\n\u001b[0;32m---> 45\u001b[0m valid_units_lowered \u001b[38;5;241m=\u001b[39m [unit\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m valid_units]\n\u001b[1;32m     46\u001b[0m orig_units_remapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(orig_units)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ch_name, unit \u001b[38;5;129;01min\u001b[39;00m orig_units\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Be lenient: we ignore case for now.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx, recording in enumerate(recordings):\n",
    "    print(idx)\n",
    "    try:\n",
    "        psg_file = [x.name for x in psg_files if x.name.startswith(recording) and x.name.endswith(\"PSG.edf\")][0]\n",
    "        hypnogram_file = [x.name for x in hypnogram_files if x.name.startswith(recording) and x.name.endswith(\"Hypnogram.edf\")][0]\n",
    "        data = mne.io.read_raw_edf(sleep_data_dir / psg_file)\n",
    "        raw_data = data.get_data()\n",
    "        \n",
    "        # Deal with hypnogram\n",
    "        hypnogram = mne.read_annotations(sleep_data_dir / hypnogram_file)\n",
    "        onsets = hypnogram.onset * sampling_rate_hz\n",
    "        durations = hypnogram.duration * sampling_rate_hz\n",
    "        descriptions = hypnogram.description\n",
    "\n",
    "        # get  'EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'EMG submental' from raw data\n",
    "        eeg_fpz_cz = raw_data[channels.index(\"EEG Fpz-Cz\"), :]\n",
    "        eeg_pz_oz = raw_data[channels.index(\"EEG Pz-Oz\"), :]\n",
    "        eog_horizontal = raw_data[channels.index(\"EOG horizontal\"), :]\n",
    "        emg_submental = raw_data[channels.index(\"EMG submental\"), :]\n",
    "\n",
    "        # trucate last stage - I assume the last duration is actually longer than the data\n",
    "        trucate_amount = ((onsets[-1]+durations[-1])) - eeg_fpz_cz.shape[0]\n",
    "        durations[-1] = durations[-1]-trucate_amount\n",
    "\n",
    "        hypnogram = pd.DataFrame({\"onset\": onsets, \"duration\": durations, \"description\": descriptions})\n",
    "        stages = hypnogram_to_labelled_data(hypnogram, sampling_rate_hz)         \n",
    "        all_data = pd.DataFrame({\"eeg_fpz_cz\": eeg_fpz_cz, \"eeg_pz_oz\": eeg_pz_oz, \"eog_horizontal\": eog_horizontal, \"emg_submental\": emg_submental, \"stage\": stages})\n",
    "        \n",
    "        # Aggregate data to 30 second windows\n",
    "        #WINDOW_SIZE_SEC = 30\n",
    "        WINDOW_SIZE_SEC = 1\n",
    "        \n",
    "        def most_frequent(x):\n",
    "            return x.value_counts().index[0]\n",
    "        agg_rules = {'eeg_fpz_cz': 'mean', 'eeg_pz_oz': 'mean', 'eog_horizontal': 'mean', 'emg_submental': 'mean', 'stage': most_frequent}\n",
    "        agg_data = all_data.groupby(all_data.index // (WINDOW_SIZE_SEC*sampling_rate_hz)).agg(agg_rules)\n",
    "\n",
    "        seconds_in_30_minutes = 30*60\n",
    "\n",
    "        # Split data into 30 minute chunks\n",
    "        \n",
    "        chunks = chunk_data(agg_data, seconds_in_30_minutes // WINDOW_SIZE_SEC)\n",
    "\n",
    "        \n",
    "        # save chunks\n",
    "        print(\"Num chunks\", len(chunks))\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            if len(chunk['stage'].unique()) == 1 and chunk['stage'].unique()[0] in ['Sleep stage W', 'Movement time', 'Sleep stage ?']:\n",
    "                continue\n",
    "            #print('saving', f\"sleep/{recording}-{i}.npy\")\n",
    "            np.save(f\"sleep/{recording}-{i}.npy\", chunk[['eeg_fpz_cz', 'eeg_pz_oz', 'eog_horizontal', 'emg_submental']].values)\n",
    "\n",
    "            idxs = find_switch_idx(chunk['stage'].values)\n",
    "            np.save(f\"sleep/{recording}-{i}-labels.npy\", chunk['stage'].values[idxs])\n",
    "\n",
    "            np.save(f\"sleep/{recording}-{i}-timestamps.npy\", np.array(idxs))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('error', recording)\n",
    "        continue\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(np.diff(idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8574000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eeg_fpz_cz)\n",
    "len(eeg_pz_oz)\n",
    "len(emg_submental)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
